[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LearningDiary",
    "section": "",
    "text": "1 Introduction\nHello, this is Yao Wang’s learning diary. I come from China. And I finished my undergraduate studies at Xi’an University of Architecture and Technology, major in Landscape Architecture. Then last year I came to UCL and studied MArch Urban Design at the Bartlett. Because I am pretty interested in coding and big scale spacial analysis, I applied second Master’s degree in CASA, Urban Spacial Science programme."
  },
  {
    "objectID": "Summary.html",
    "href": "Summary.html",
    "title": "2  Introduction",
    "section": "",
    "text": "Hi, this is Yao Wang. I am a student of CASA Urban Spatial Science programme. After five years study of Landscape Achitecture. I learned a lot about urban develpoment and environment issues. After my undergraduate study, I chose to study Urban Design in the Bartlett. During this time period, I realized that data analysis is quiet important in urban studies. So I continue my study in this area, hoping to learn data analysis methods in a systematic way."
  },
  {
    "objectID": "Getting started with remote sensing.html#summary",
    "href": "Getting started with remote sensing.html#summary",
    "title": "2  Getting Started with Remote Sensing",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nIn this week, we begin to explore the area of remote sensing data and related analysis methods. In this I learned the basics of loading sentinel and landsat data. Knowing the difference between active and passive romote sensing and how the electromagnetic waves interact with Earth’s surface and atmosphere. And be familiar with four resolutions of remotely sensed data. QGIS, SNAP and R are also used in practical for preliminary analysis of remote sensing data such as resampling, cropping, correction etc(butcher_tour_2016?)."
  },
  {
    "objectID": "Getting started with remote sensing.html#application",
    "href": "Getting started with remote sensing.html#application",
    "title": "2  Getting Started with Remote Sensing",
    "section": "2.2 Application",
    "text": "2.2 Application\nRemote sensing is achieved by detecting the ground target, acquiring information about the target, and then processing the information acquired so that it can understand and describe the target, it acquires information through sensors. The sensors collect information from the surface of the ground which is the electromagnetic waves radiated from the surface of any feature and the reflected incident electromagnetic waves.\nOne application of this is the analysis of remotely sensed imagery through the reflectance of a feature’s wave spectrum. The reflectance spectrum of an object is limited to the ultraviolet, visible and infrared bands, especially the latter two. The characteristics of an object’s reflectance spectrum depend largely on the choice of wavelength at which the object interacts with the incident radiation. As shown in the figure below, the reflectance spectra of four features - citrus, tomato, maize and cotton - have different shapes(brady_remote_2021?). The different reflectance of features in different wavelengths makes it easy to think of using multiple wavelengths for feature detection, such as multi-spectral scanners and other sensors for feature spectral analysis and identification, and through the fusion of remote sensing data from multiple sources and false color synthesis, which is becoming an important way of processing remote sensing images. It is also because of the characteristic that different features have different reflectance at different wavelengths that the reflectance curves of objects are widely used in the analysis and evaluation of remote sensing images as a physical basis for interpretation and classification.\n\n\n\nCharacteristic curves of reflection spectra of four plants(__2022-1?)\n\n\nSatellite radar images and ancillary information can also be used in other areas. For example, we can use it to detect flood areas at their peak and evaluates its potential with mapping. The procedure wass tested on the catastrophic flood that occurred in Italy. Two ERS-1 synthetic aperture radar(SAR) images were processed, one acquired one month before the flood and the other acquired three days after the event. Visual interpretation and two different thresholding techniques were performed. The flood map derived shows only a small fraction of the satellite overpass. To overcome this limitation, the authors developed a new method to estimate the flooded area at the peak time by integrating the flooded area from SAR imagery with digital topographic data from GIS technique(brivio2002?).\n\n\n\nTemporal relationships between flood event(2021uk2021?)\n\n\nSome recent studies also shown UAV remote sensing techniques have many applications. Like spatial ecology, forest studies and other monitoring applications(‘Unmanned aerial vehicles for environmental applications’,2017). Before the development of UAVs, the majority of spectral datasets was made by satellites and manned aircraft(aasen_quantitative_2018?). By the rapidly developing technology, many new types of sensors make data quality assurance. For example, this picture shows the process from collect information to make data product(aasen_quantitative_2018?)."
  },
  {
    "objectID": "Getting started with remote sensing.html#personal-reflection",
    "href": "Getting started with remote sensing.html#personal-reflection",
    "title": "2  Getting Started with Remote Sensing",
    "section": "2.3 Personal reflection",
    "text": "2.3 Personal reflection\nWhen I first came across the analysis of remote sensing data, I felt that a wide range of physics, electronics, space science and information science are used in the acquisition of remote sensing data. It is its comprehensive nature that makes it such an interesting discipline, and with the help of remote sensing technology we are able to see the world from a different perspective.\nFor example, through PCA analysis. We can obtain remote sensing images that highlight the required elements, which helps us to carry out further analysis on a large scale. When doing the practical in this chapter, I always had some minor problems in the process of using snap, such as the failure to recognize the formulae in the next step due to resampling failure, and sometimes computer memory problems in the calculation, which I did not find at the beginning and only solved through many attempts."
  },
  {
    "objectID": "Corrections.html#summary",
    "href": "Corrections.html#summary",
    "title": "5  Corrections",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nDue to the spatial, spectral, temporal and radiometric resolution limitations of remote sensing systems, it is difficult to accurately record information on complex land surfaces and therefore errors are inevitable in the process of data acquisition. These errors reduce the quality of the remote sensing data and the accuracy of the image analysis. Therefore it is necessary to pre-process the remote sensing images before the actual image analysis and processing. In this week, we mainly focused on corrections and data joining and enhancement. In corrections part, it includes geometric correction, atmospheric correction, orthorectification/topographic correction and radiometric correction. Image joining can help us combine several image for the analysis of bigger area and image enhancements can improve the visual appearance or results. In the practical, we tried to use landsat data to do some analysis, first we should correction and merge image, and then highlight the area with healthy vegetation. Finally, we did PCA analysis."
  },
  {
    "objectID": "Corrections.html#application",
    "href": "Corrections.html#application",
    "title": "5  Corrections",
    "section": "5.2 Application",
    "text": "5.2 Application\nIn the processing and analysis of remote sensing imagery, raw remote sensing data often contain such severe geometric distortions that they are difficult to integrate with other data. Each EO image acquisition system produces unique geometric distortions in its original images, so that the geometry of these images in their own local coordinate system does not correspond to other images, terrain and the user’s particular map projection. The sources of distortion can be divided into two main categories: the observer, the acquisition system, and the observed. In addition to these distortions, distortions associated with map projections need to be considered (Toutin 2011).\n\n\n\nSource: State of the art of geometric correction of remote sensing data: a data fusion perspective\n\n\nPre-processing is the initial and most basic image operation, correcting image distortions that occur during the image data acquisition process and restoring image quality. The elimination of geometric distortion is called geometric correction and the elimination of radiation distortion is called radiometric correction. In practice, atmospheric correction and topographic correction are usually carried out. The diagram below is an example of a geometric correction, the operations of which require geometrical mathematics and elevation information for better geolocation (Toutin 2011).\n\n\n\nImage rectification to project the uncorrected image into the ground reference system: the geometric(Left) and radiometric(right) operations\n\n\nObservations of tropical rainforest vegetation dynamics using satellite-based remote sensing data are presented in a paper. There is some uncertainty in the data due to atmospheric corrections and cloud cover. In their study they used the Moderate Resolution Imaging Spectroradiometer (MODIS) and derived composites (MYDO9A1, MCD43A4 and MYD13A2 - vegetation indices) on board the Aqua satellite with results obtained from the Atmospheric Multi Angle Implementation for Correction (MAIAC) algorithm to assess these uncertainties. MAIAC employs a new cloud screening technique, as well as a new aerosol retrieval and atmospheric correction procedure based on time series and spatial analysis. Their results show a considerable improvement in surface reflectance and a 10-fold reduction in image noise levels using the MAlAC treatment(Hilker et al. 2012).\n\n\n\nSource: Remote sensing of tropical ecosystems: Atmospheric correction and cloud masking matter\n\n\nMonthly observations of NDVI from MYD09GA (1 km daily surface reflectance), MYD09A1 (8 day composites),MYD13A2 (16 day vegetation index product) and MAIAC obtained over a 50 × 50 km area as indicated in the map. The er rorbars represent the mean spatial variability over the 50 × 50fkm subset (Please note that the points and errorbars of the products are slightly offset from each other for purposes of readability).\n\n\n\nSource: Remote sensing of tropical ecosystems: Atmosph eric correction and cloud masking matter\n\n\nComparison of MYD09/MYD35 and MAIAC cloud mask. (A) False color infrared image acquired over the study area on July 16, 2002. (B) MYD09/MYD35 derived cloud mask overlaid on top of the same image (C)MAIAC derived c loud mask.\nFor image mosaics, when our study area exceeds the coverage of a single remote sensing image, it is often necessary to stitch together two or more images to form a larger image or series of images that cover the whole area, and this is the process of image mosaics.\nThe goal of image enhancement is to highlight relevant thematic information and improve the visual impact of the image; the goal of image transformation is to make it easier for the analyst to identify the content of the image and extract more useful information from it. Both are usually carried out after image correction and reconstruction, particularly where various types of noise in the original image must be removed."
  },
  {
    "objectID": "Corrections.html#personal-reflection",
    "href": "Corrections.html#personal-reflection",
    "title": "5  Corrections",
    "section": "5.3 Personal reflection",
    "text": "5.3 Personal reflection\nThis week I have been learning how to pre-process remote sensing images, including image correction, image mosaicing and enhancement. In this I learnt that there are so many reasons for distortion in remote sensing images and the need to pre-process images. After doing the calculations for ndvi, I found that the image enhancement process was more scientific than I had previously thought.\n\n\n\n\nHilker, Thomas, Alexei I. Lyapustin, Compton J. Tucker, Piers J. Sellers, Forrest G. Hall, and Yujie Wang. 2012. “Remote Sensing of Tropical Ecosystems: Atmospheric Correction and Cloud Masking Matter.” Remote Sensing of Environment 127 (December): 370–84. https://doi.org/10.1016/j.rse.2012.08.035.\n\n\nToutin, Thierry. 2011. “State-of-the-Art of Geometric Correction of Remote Sensing Data: A Data Fusion Perspective.” International Journal of Image and Data Fusion 2 (1): 3–35. https://doi.org/10.1080/19479832.2010.539188."
  },
  {
    "objectID": "Policy.html#summary-of-the-policy-and-city-selected",
    "href": "Policy.html#summary-of-the-policy-and-city-selected",
    "title": "6  Policy",
    "section": "6.1 Summary of the policy and city selected",
    "text": "6.1 Summary of the policy and city selected\nThe city I seleced is Ahmedabad(Gujarat, India). And the related policy is South Asia’s First Heat-health Action Plan(Kadhim, Mourshed, and Bray 2016) and Ahmedabad Heat Action Plan 2016. It is well known and documented that urbanisation can have significant effects on local weather and climate. Of these effects one of the most familiar is the urban heat island, for which the temperatures of the central urban locations are several degrees higher than those of nearby rural areas of simialr elevation. As a rapidly growing city in South Asia, it would be worsen in a warming city(Hilker et al. 2012).\nAs one of the hottest city in India. The city of Ahmedabad is in the largest district in the western Indian state of Gujarat. With a population of 7.2 million and rapid growth in the real estate, automotive, and pharmaceutical sectors, Ahmedabad is among the top ten fastest growing cities in India, and is poised to become one of India’s leading metropolises by 2020.\nAt the time of the 2010 heat wave, the population of Ahmedabad was no better protected than those of other major South Asian cities. HAPs are comprehensive extreme heat early warning systems and prepardness plans. They typically include a range of mitigation and adaptation measures aimed at reducing health impacts in both the short and longer term. Their goal is to improve public awareness, expedite community outreach, facilitate coordincation across sectors, support capacity building for health care professionals, promote adaptation efforts, and reduce heat exposure, illness, and death.\nThis picture shows the May 2010 temperature and mortality as compared to the averages in May 2009 and 2011. The graph of mortality shows a large rise in daily mortality in 2010 coinciding with the heat wave.\n\n\n\nsource:Ahmedabad Heat Action Plan"
  },
  {
    "objectID": "Policy.html#remotely-sensed-datacontribute-to-the-policy-goal",
    "href": "Policy.html#remotely-sensed-datacontribute-to-the-policy-goal",
    "title": "6  Policy",
    "section": "6.2 Remotely sensed data(contribute to the policy goal)",
    "text": "6.2 Remotely sensed data(contribute to the policy goal)\nIn a study of urban heat islands in Beijing, the paper attempts to identify urban heat island patches by remote sensing and to investigate their spatial expansion paths. In this study, MODIS surface temperature data products are used and a probabilistic threshold algorithm is introduced to improve the spatial identification accuracy of urban heat island patches. Based on this, an urban heat island expansion index is constructed to decompose the spatial and temporal change process of urban heat island patches into flying terrain, edge type, infill type and shrinkage type patterns. Based on the land use change process, the path analysis of the spatial expansion pattern of urban heat island patches is carried out to accurately identify the sources and trends of the spatial expansion path of urban heat island patches.\nThis study shows that the area of the diurnal urban heat island patches in Beijing in the summer of 2020 will be 3932km² and 2266km² respectively, accounting for 23.96% and 13.81% of the total area of Beijing. The proportion of diurnal urban heat island patch area increases by 43.40% and 24.44% respectively between 2005 and 2020 in summer. The area of growing urban heat island patches is greater than the area of shrinking urban heat island patches. The edge-type sprawl pattern is the most dominant pattern for growing urban heat island patches. Arable land, urban building land and rural settlements are the main spatial expansion paths for growing urban heat island patches. The results of this study provide a theoretical basis and data support to reveal the formation process of urban thermal environment and its fine management (Airola et al. 2019)."
  },
  {
    "objectID": "Policy.html#how-it-advances-current-local-national-or-global-approaches",
    "href": "Policy.html#how-it-advances-current-local-national-or-global-approaches",
    "title": "6  Policy",
    "section": "6.3 How it advances current local, national or global approaches",
    "text": "6.3 How it advances current local, national or global approaches\nGovernment departments can use urban heat island data to assist in identifying areas of the city that are more severely affected, and then optimise spatial functions by improving the layout of their edges during urban planning to achieve the realistic need to slow down the intensification and control the expansion of urban heat islands. Temperature data can also be overlaid with other types of data, such as vegetation data and the number of people suffering from diseases, to provide data to identify the causes of urban problems.\n\n\n\n\nAirola, Antti, Jonne Pohjankukka, Johanna Torppa, Maarit Middleton, Vesa Nykänen, Jukka Heikkonen, and Tapio Pahikkala. 2019. “The Spatial Leave-Pair-Out Cross-Validation Method for Reliable AUC Estimation of Spatial Classifiers.” Data Mining and Knowledge Discovery 33 (3): 730–47. https://doi.org/10.1007/s10618-018-00607-x.\n\n\nHilker, Thomas, Alexei I. Lyapustin, Compton J. Tucker, Piers J. Sellers, Forrest G. Hall, and Yujie Wang. 2012. “Remote Sensing of Tropical Ecosystems: Atmospheric Correction and Cloud Masking Matter.” Remote Sensing of Environment 127 (December): 370–84. https://doi.org/10.1016/j.rse.2012.08.035.\n\n\nKadhim, Nada, Monjur Mourshed, and Michaela Bray. 2016. “Advances in Remote Sensing Applications for Urban Sustainability.” Euro-Mediterranean Journal for Environmental Integration 1 (1): 7. https://doi.org/10.1007/s41207-016-0007-4."
  },
  {
    "objectID": "GoogleEarthEngine.html#summary",
    "href": "GoogleEarthEngine.html#summary",
    "title": "7  Google Earth Engine",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nIn this week we learned about the Google Earth Engine, including its set up, basic functions and how to use it to process remote sensing data. The GEE platform combines the powerful computing power provided by Google servers with a large range of cloud computing resources. The platform dataset provides a large and complete set of imagery from Earth observation satellites such as Sentinel, MODIS, Landsat, etc., as well as vegetation, surface temperature and socio-economic datasets. GEE provides both Python and JavaScript versions of the editing interface for rapid, interactive algorithm development using a web-based code editor. It has the very outstanding advantage of having a huge amount of data that can be called up online and a wide range of data sources, without the need to search and download according to different data from different internet sources. What’s more, it does not need to occupy the memory of one’s own computer and enables online cloud computing."
  },
  {
    "objectID": "GoogleEarthEngine.html#application",
    "href": "GoogleEarthEngine.html#application",
    "title": "7  Google Earth Engine",
    "section": "7.2 Application",
    "text": "7.2 Application\nGoogle Earth Engine provides a variety of capabilities to perform spatial and spectral operations on a single image or a batch of images. These operations have great potential to be implemented in parallel on a cloud architecture, as shown in the figure below(Amani et al. 2020) . .\n\n\n\nSource: Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review\n\n\nIn recent years, GEE has been used in geomorphology, ecology, atmospheric studies, geology, natural hazards, scientific research and other fields(Yang et al. 2019)，It is an important tool for studying global environmental change. In a study of the Chengdu-Chongqing region of China, GEE and machine learning were used to extract impermeable urban surfaces. This article constructs classification features for spectral bands, spectral indices and texture indices based on the GEE cloud platform and Landsat8 imagery, using five machine learning algorithms: minimum distance (MD), categorical regression tree (CART), support vector machine (SVM), random forest (RF) and simple Bayesian (NB) ，extract of impermeable surface information. The results show that the RF algorithm works best and the extraction results are the most consistent with reality, with little difference in accuracy between the CART and SVM algorithms."
  },
  {
    "objectID": "GoogleEarthEngine.html#personal-reflection",
    "href": "GoogleEarthEngine.html#personal-reflection",
    "title": "7  Google Earth Engine",
    "section": "7.3 Personal reflection",
    "text": "7.3 Personal reflection\nDuring this week I have learnt about the power of GEE and its advantages in visualising remotely sensed data, easy access to a wide range of geographical data and a unified coordinate system. And the platform offers the ability to share code between scripts, allowing us to save a lot of time when using it. Compared to traditional imaging tools such as ENVI, Google Earth Engine allows for fast, batch processing of quantitative images. It allows rapid calculation of vegetation indices such as NDVI, for example, and can predict crop-related yields, monitor changes in drought growth, detect global forest changes and much more.\n\n\n\n\nAmani, Meisam, Arsalan Ghorbanian, Seyed Ali Ahmadi, Mohammad Kakooei, Armin Moghimi, S. Mohammad Mirmazloumi, Sayyed Hamed Alizadeh Moghaddam, et al. 2020. “Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 13: 5326–50. https://doi.org/10.1109/JSTARS.2020.3021052.\n\n\nYang, Junhuai, Zhibao Dong, Zhengyao Liu, Weikang Shi, Guoxiang Chen, Tianjie Shao, and Hanmin Zeng. 2019. “Migration of Barchan Dunes in the Western Quruq Desert, Northwestern China.” Earth Surface Processes and Landforms 44 (10): 2016–29. https://doi.org/10.1002/esp.4629."
  },
  {
    "objectID": "Classification1.html#summary",
    "href": "Classification1.html#summary",
    "title": "8  ClassificationⅠ",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis week we are learning about the classification of remote sensing images, which can be used for a variety of purposes such as urban sprawl analysis, urban green space analysis, forest fire monitoring and more. The purpose of image classification is to classify each image element in an image into different categories according to certain rules and algorithms based on its spectral brightness, spatial structure characteristics or other information in different bands. Depending on the degree of human involvement in the classification process, image classification can be classified as supervised classification, unsupervised classification and a mixture of both. In practical, we try to use GEE to perform classification operations on remote sensing data."
  },
  {
    "objectID": "Classification1.html#application",
    "href": "Classification1.html#application",
    "title": "8  ClassificationⅠ",
    "section": "8.2 Application",
    "text": "8.2 Application\nThe process of classification processing of remote sensing images is generally: image selection, image pre-processing, extraction of training data, classification, post classification processing and accuracy verification.\nThere are many applications regarding the classification of remote sensing images. In one paper, the author used support vector machines for classification in remote sensing. This paper reports the results of two experiments in which multi-class SVMs are compared with maximum likelihood (ML) and artificial neural network (ANN) methods in terms of classification accuracy. And the results show that the SVM achieves a higher level of classification accuracy than either the ML or the ANN, then we can use SVM with high-dimensional data and small training datasets(Pal and Mather 2005).\nIn another study, the authors used decision tree regression for soft classification of remote sensing data. In recent years, decision tree classification has been widely used to classify land cover from remote sensing data. In this paper, the authors employ a decision tree regression approach to determine class proportions within a pixel so as to produce soft classification from remote sensing data(Xu et al. 2005)."
  },
  {
    "objectID": "Classification1.html#personal-reflection",
    "href": "Classification1.html#personal-reflection",
    "title": "8  ClassificationⅠ",
    "section": "8.3 Personal reflection",
    "text": "8.3 Personal reflection\nThis week we have been studying the classification of remote sensing imagery, in which there are mainly supervised and unsupervised classifications, which are also widely used in the production of thematic maps. In the course of my studies I felt that there are many ways to classify remote sensing images, but the choice of method should be based on the purpose of the application and the operability of the algorithm.\n\n\n\n\nPal, M., and P. M. Mather. 2005. “Support Vector Machines for Classification in Remote Sensing.” International Journal of Remote Sensing 26 (5): 1007–11. https://doi.org/10.1080/01431160512331314083.\n\n\nXu, M, P Watanachaturaporn, P Varshney, and M Arora. 2005. “Decision Tree Regression for Soft Classification of Remote Sensing Data.” Remote Sensing of Environment 97 (3): 322–36. https://doi.org/10.1016/j.rse.2005.05.008."
  },
  {
    "objectID": "Classification2.html#summary",
    "href": "Classification2.html#summary",
    "title": "9  ClassificationⅡ",
    "section": "9.1 Summary",
    "text": "9.1 Summary\nIn this week we continued our study of remote sensing image classification and accuracy analysis. This chapter is very extensive and difficult to understand. The classification section covers both image element based classification and object oriented classification. The verification of the correct classification of remote sensing images is also part of the quantitative analysis of remote sensing images. It is generally not possible to test each image element against the whole classification result, but rather to estimate the classification error using some reference sampling data."
  },
  {
    "objectID": "Classification2.html#application",
    "href": "Classification2.html#application",
    "title": "9  ClassificationⅡ",
    "section": "9.2 Application",
    "text": "9.2 Application\nImage element-based classification takes into account the intensity information of the image element’s waveband spectral features(Chen et al. 2009). However, spatial structural relationships and contextual semantic information features are ignored.\nObject-oriented remote sensing image classification, the smallest unit of processing is no longer an image element, but an image object composed of multiple adjacent image elements containing more semantic information, and the geometric information of the object is used more in the classification than just the spectral information of a single object (Blaschke 2010a).\nIn related research, Geographical Object Based Image Analysis (GEOBIA) refers to a class of digital remote sensing image analysis methods that study geographical entities or phenomena by depicting and analysing image objects rather than individual pixels. Image objects are usually represented by clusters of similar neighbouring pixels that share a common reference or meaning. A unique feature of GEOBIA, compared to traditional pixel-by-pixel modelling methods, is that image objects (usually from segmentation) - rather than individual pixels - become the basic unit of analysis because they represent “meaningful” geographical entities or phenomena at multiple scales(Blaschke 2010b) .\n\n\n\nSource:Geographic object-based image analysis (GEOBIA): emerging trends and future opportunities"
  },
  {
    "objectID": "Classification2.html#personal-reflection",
    "href": "Classification2.html#personal-reflection",
    "title": "9  ClassificationⅡ",
    "section": "9.3 Personal reflection",
    "text": "9.3 Personal reflection\nThe content and accuracy analysis of remote sensing image classification involves a very wide range of content and concepts. In this I have realized that different analysis methods should be adopted when dealing with different data and usage scenarios. When analysing remotely sensed data, there are different definitions of accuracy of classification in different contexts.\n\n\n\n\nBlaschke, T. 2010a. “Object Based Image Analysis for Remote Sensing.” ISPRS Journal of Photogrammetry and Remote Sensing 65 (1): 2–16. https://doi.org/10.1016/j.isprsjprs.2009.06.004.\n\n\n———. 2010b. “Object Based Image Analysis for Remote Sensing.” ISPRS Journal of Photogrammetry and Remote Sensing 65 (1): 2–16. https://doi.org/10.1016/j.isprsjprs.2009.06.004.\n\n\nChen, Jin, Xiuping Jia, Wei Yang, and Bunkei Matsushita. 2009. “Generalization of Subpixel Analysis for Hyperspectral Data with Flexibility in Spectral Similarity Measures.” IEEE Transactions on Geoscience and Remote Sensing 47 (7): 2165–71. https://doi.org/10.1109/TGRS.2008.2011432."
  },
  {
    "objectID": "Temperature.html#summary",
    "href": "Temperature.html#summary",
    "title": "10  Temperature and policy",
    "section": "10.1 Summary",
    "text": "10.1 Summary\nDuring the week we learnt about the application of remote sensing data to urban temperature analysis and the policies associated with it at different spatial scales. More specifically I learnt about what the urban heat island effect is and how it is formed, and how the heat island effect can be harmful to cities. Many cities have developed their own policies to address the heat island effect, and there is a growing concern about the urban thermal environment at both the global and local scales, and a variety of technical approaches are being used to address these issues."
  },
  {
    "objectID": "Temperature.html#application",
    "href": "Temperature.html#application",
    "title": "10  Temperature and policy",
    "section": "10.2 Application",
    "text": "10.2 Application\nRegarding the urban heat island effect, there are currently three main methods of research on this phenomenon: first, the ground observation method, mainly based on information from ground weather stations and supplementary fixed-point measurements, to analyze and compare the data; second, the use of remote sensing and GIS technology, mainly using satellite remote sensing technology to invert and project the surface temperature and use GIS technology to analyze and research; third, the numerical simulation method (Blaschke 2010)，atmospheric and spatial modelling using meteorological and other data to study changes in the urban heat island effect.\nIn an article the authors examine how inequalities in local structures may have a significant impact on the health of vulnerable groups. Historic urban policies, such as redlining, have contributed to the current inequalities in exposure to intra-urban heat. But it is not clear whether these heat inequalities are associated with heat-related health disparities among people. Data from two Texas cities were used in this study and the relationship between heat conditions within the cities and heat-related emergency room visits was determined. Heat exposure was measured using diurnal ground surface temperature (LST)."
  },
  {
    "objectID": "Temperature.html#personal-reflection",
    "href": "Temperature.html#personal-reflection",
    "title": "10  Temperature and policy",
    "section": "10.3 Personal reflection",
    "text": "10.3 Personal reflection\nThis week we have been learning about remote sensing in relation to urban temperature and related policies. As cities expand and develop, so does the urban climate. However, in the development of policies, there is often vague and empty rhetoric that can make it difficult to guide the planning of the next city. The use of remote sensing data analysis techniques can provide a degree of accuracy that can help researchers to quantify these issues and draw more accurate conclusions.\n\n\n\n\nBlaschke, T. 2010. “Object Based Image Analysis for Remote Sensing.” ISPRS Journal of Photogrammetry and Remote Sensing 65 (1): 2–16. https://doi.org/10.1016/j.isprsjprs.2009.06.004."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Pal, M., and P. M. Mather. 2005. “Support Vector Machines for\nClassification in Remote Sensing.” International Journal of\nRemote Sensing 26 (5): 1007–11. https://doi.org/10.1080/01431160512331314083.\n\n\nXu, M, P Watanachaturaporn, P Varshney, and M Arora. 2005.\n“Decision Tree Regression for Soft Classification of Remote\nSensing Data.” Remote Sensing of Environment 97 (3):\n322–36. https://doi.org/10.1016/j.rse.2005.05.008."
  },
  {
    "objectID": "Gettingstartedwithremotesensing.html#summary",
    "href": "Gettingstartedwithremotesensing.html#summary",
    "title": "3  Getting Started with Remote Sensing",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nIn this week, we begin to explore the area of remote sensing data and related analysis methods. In this I learned the basics of loading sentinel and landsat data. Knowing the difference between active and passive romote sensing and how the electromagnetic waves interact with Earth’s surface and atmosphere. And be familiar with four resolutions of remotely sensed data. QGIS, SNAP and R are also used in practical for preliminary analysis of remote sensing data such as resampling, cropping, correction etc(Butcher 2016)."
  },
  {
    "objectID": "Gettingstartedwithremotesensing.html#application",
    "href": "Gettingstartedwithremotesensing.html#application",
    "title": "3  Getting Started with Remote Sensing",
    "section": "3.2 Application",
    "text": "3.2 Application\nRemote sensing is achieved by detecting the ground target, acquiring information about the target, and then processing the information acquired so that it can understand and describe the target, it acquires information through sensors. The sensors collect information from the surface of the ground which is the electromagnetic waves radiated from the surface of any feature and the reflected incident electromagnetic waves.\nOne application of this is the analysis of remotely sensed imagery through the reflectance of a feature’s wave spectrum. The reflectance spectrum of an object is limited to the ultraviolet, visible and infrared bands, especially the latter two. The characteristics of an object’s reflectance spectrum depend largely on the choice of wavelength at which the object interacts with the incident radiation. As shown in the figure below, the reflectance spectra of four features - citrus, tomato, maize and cotton - have different shapes(Brady 2021). The different reflectance of features in different wavelengths makes it easy to think of using multiple wavelengths for feature detection, such as multi-spectral scanners and other sensors for feature spectral analysis and identification, and through the fusion of remote sensing data from multiple sources and false color synthesis, which is becoming an important way of processing remote sensing images. It is also because of the characteristic that different features have different reflectance at different wavelengths that the reflectance curves of objects are widely used in the analysis and evaluation of remote sensing images as a physical basis for interpretation and classification.\n\n\n\nCharacteristic curves of reflection spectra of four plants(Aasen et al. 2018a)\n\n\nSatellite radar images and ancillary information can also be used in other areas. For example, we can use it to detect flood areas at their peak and evaluates its potential with mapping. The procedure wass tested on the catastrophic flood that occurred in Italy. Two ERS-1 synthetic aperture radar(SAR) images were processed, one acquired one month before the flood and the other acquired three days after the event. Visual interpretation and two different thresholding techniques were performed. The flood map derived shows only a small fraction of the satellite overpass. To overcome this limitation, the authors developed a new method to estimate the flooded area at the peak time by integrating the flooded area from SAR imagery with digital topographic data from GIS technique(Brivio et al. 2002).\n\n\n\nTemporal relationships between flood event(“2021 UK Greenhouse Gas Emissions, Provisional Figures” 2021)\n\n\nSome recent studies also shown UAV remote sensing techniques have many applications. Like spatial ecology, forest studies and other monitoring applications(‘Unmanned aerial vehicles for environmental applications’,2017). Before the development of UAVs, the majority of spectral datasets was made by satellites and manned aircraft(Aasen et al. 2018b). By the rapidly developing technology, many new types of sensors make data quality assurance. For example, this picture shows the process from collect information to make data product(Aasen et al. 2018c)."
  },
  {
    "objectID": "Gettingstartedwithremotesensing.html#personal-reflection",
    "href": "Gettingstartedwithremotesensing.html#personal-reflection",
    "title": "3  Getting Started with Remote Sensing",
    "section": "3.3 Personal reflection",
    "text": "3.3 Personal reflection\nWhen I first came across the analysis of remote sensing data, I felt that a wide range of physics, electronics, space science and information science are used in the acquisition of remote sensing data. It is its comprehensive nature that makes it such an interesting discipline, and with the help of remote sensing technology we are able to see the world from a different perspective.\nFor example, through PCA analysis. We can obtain remote sensing images that highlight the required elements, which helps us to carry out further analysis on a large scale. When doing the practical in this chapter, I always had some minor problems in the process of using snap, such as the failure to recognize the formulae in the next step due to resampling failure, and sometimes computer memory problems in the calculation, which I did not find at the beginning and only solved through many attempts.\n\n\n\n\n“2021 UK Greenhouse Gas Emissions, Provisional Figures.” 2021.\n\n\nAasen, Helge, Eija Honkavaara, Arko Lucieer, and Pablo Zarco-Tejada. 2018a. “Quantitative Remote Sensing at Ultra-High Resolution with UAV Spectroscopy: A Review of Sensor Technology, Measurement Procedures, and Data Correction Workflows.” Remote Sensing 10 (7): 1091. https://doi.org/10.3390/rs10071091.\n\n\n———. 2018b. “Quantitative Remote Sensing at Ultra-High Resolution with UAV Spectroscopy: A Review of Sensor Technology, Measurement Procedures, and Data Correction Workflows.” Remote Sensing 10 (7): 1091. https://doi.org/10.3390/rs10071091.\n\n\n———. 2018c. “Quantitative Remote Sensing at Ultra-High Resolution with UAV Spectroscopy: A Review of Sensor Technology, Measurement Procedures, and Data Correction Workflows.” Remote Sensing 10 (7): 1091. https://doi.org/10.3390/rs10071091.\n\n\nBrady, Maria. 2021. “Remote Sensing for Dummies.” https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d.\n\n\nBrivio, P. A., R. Colombo, M. Maggi, and R. Tomasoni. 2002. “Integration of Remote Sensing Data and GIS for Accurate Mapping of Flooded Areas.” International Journal of Remote Sensing 23 (3): 429–41. https://doi.org/10.1080/01431160010014729.\n\n\nButcher, Ginger. 2016. Tour of the Electromagnetic Spectrum. Third edition. Washington, DC: National Aeronautics; Space Administration."
  },
  {
    "objectID": "Portfolio.html#section",
    "href": "Portfolio.html#section",
    "title": "4  Portfolio",
    "section": "4.1 ",
    "text": "4.1"
  }
]